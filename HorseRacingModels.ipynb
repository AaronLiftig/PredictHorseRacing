{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Racing Dataset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "#Supresses scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>race_number</th>\n",
       "      <th>market_name</th>\n",
       "      <th>previous_margin</th>\n",
       "      <th>position_again</th>\n",
       "      <th>bf_odds</th>\n",
       "      <th>bf_odds_two_mins_out</th>\n",
       "      <th>vic_tote</th>\n",
       "      <th>vic_tote_two_mins_out</th>\n",
       "      <th>...</th>\n",
       "      <th>track_win_percent_norm</th>\n",
       "      <th>track_place_percent_norm</th>\n",
       "      <th>distance_win_percent_norm</th>\n",
       "      <th>distance_place_percent_norm</th>\n",
       "      <th>condition_win_percent_norm</th>\n",
       "      <th>condition_starts_norm</th>\n",
       "      <th>condition_place_percent_norm</th>\n",
       "      <th>prize_money_per_start_norm</th>\n",
       "      <th>bf_odds_place</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Echuca</td>\n",
       "      <td>3</td>\n",
       "      <td>R3 1200m Mdn</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Echuca</td>\n",
       "      <td>3</td>\n",
       "      <td>R3 1200m Mdn</td>\n",
       "      <td>20.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>11.20</td>\n",
       "      <td>11.70</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Echuca</td>\n",
       "      <td>3</td>\n",
       "      <td>R3 1200m Mdn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>46.40</td>\n",
       "      <td>37.10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.29</td>\n",
       "      <td>21.20</td>\n",
       "      <td>21.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Echuca</td>\n",
       "      <td>3</td>\n",
       "      <td>R3 1200m Mdn</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>13.20</td>\n",
       "      <td>14.20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.11</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Echuca</td>\n",
       "      <td>3</td>\n",
       "      <td>R3 1200m Mdn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date venue_name  race_number   market_name  previous_margin  \\\n",
       "0  2016-06-27     Echuca            3  R3 1200m Mdn             6.80   \n",
       "1  2016-06-27     Echuca            3  R3 1200m Mdn            20.80   \n",
       "2  2016-06-27     Echuca            3  R3 1200m Mdn              NaN   \n",
       "3  2016-06-27     Echuca            3  R3 1200m Mdn             4.00   \n",
       "4  2016-06-27     Echuca            3  R3 1200m Mdn              NaN   \n",
       "\n",
       "   position_again  bf_odds  bf_odds_two_mins_out  vic_tote  \\\n",
       "0            1.00     2.88                  3.00      2.30   \n",
       "1            2.00    15.00                 18.00     11.20   \n",
       "2            3.00    95.00                100.00     46.40   \n",
       "3             NaN    20.00                 17.00     13.20   \n",
       "4             NaN     2.74                  2.68      2.60   \n",
       "\n",
       "   vic_tote_two_mins_out  ...  track_win_percent_norm  \\\n",
       "0                   3.50  ...                     NaN   \n",
       "1                  11.70  ...                     NaN   \n",
       "2                  37.10  ...                     NaN   \n",
       "3                  14.20  ...                     NaN   \n",
       "4                   3.20  ...                     NaN   \n",
       "\n",
       "   track_place_percent_norm  distance_win_percent_norm  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "   distance_place_percent_norm  condition_win_percent_norm  \\\n",
       "0                         1.00                         NaN   \n",
       "1                         1.00                         NaN   \n",
       "2                         0.00                         NaN   \n",
       "3                         0.00                         NaN   \n",
       "4                         0.00                         NaN   \n",
       "\n",
       "   condition_starts_norm  condition_place_percent_norm  \\\n",
       "0                   0.00                           NaN   \n",
       "1                   0.33                           NaN   \n",
       "2                   1.00                           NaN   \n",
       "3                   0.00                           NaN   \n",
       "4                   0.00                           NaN   \n",
       "\n",
       "  prize_money_per_start_norm bf_odds_place target  \n",
       "0                       0.20          1.63   2.88  \n",
       "1                       0.47          4.20   4.20  \n",
       "2                       0.29         21.20  21.20  \n",
       "3                       0.11          5.27   0.00  \n",
       "4                       0.08          1.60   0.00  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires CleanedHorses.csv, which was created in the HorseRacingDataCleaning notebook\n",
    "df_cleaned = pd.read_csv('CleanedHorses.csv',\n",
    "                         skipinitialspace=True, \n",
    "                         low_memory=False)\n",
    "\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop('position_again', axis=1, inplace=True)\n",
    "\n",
    "# Eliminating columns that cannot be easily converted into dummy variables\n",
    "df_cleaned.drop(['name', 'runner_name_uuid', 'sire', 'dam', 'jockey', 'trainer'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty_norm               238331.00\n",
       "runs_since_spell_norm      238331.00\n",
       "firm_starts_norm           128042.00\n",
       "firm_wins_norm             198389.00\n",
       "firm_places_norm           176606.00\n",
       "heavy_wins_norm            128625.00\n",
       "class_same_wins_norm       120453.00\n",
       "class_stronger_wins_norm   134189.00\n",
       "track_distance_wins_norm   128373.00\n",
       "distance_norm              238331.00\n",
       "track_win_percent_norm     146614.00\n",
       "track_place_percent_norm   122103.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isna().sum().where(lambda x: x>df_cleaned.shape[0]*.5).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop(['penalty_norm', 'runs_since_spell_norm', 'distance_norm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.set_index(['date','venue_name','race_number','market_name'], inplace=True)\n",
    "df_cleaned.sort_index(level=['date','venue_name','race_number'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['uniq_idx'] = range(len(df_cleaned))\n",
    "df_cleaned.set_index('uniq_idx', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = list(df_cleaned.select_dtypes('object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.get_dummies(df_cleaned, columns=categorical_list, dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_list = list(df_cleaned.select_dtypes('number').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_list:\n",
    "    if df_cleaned[col].isna().sum() != 0:\n",
    "        df_cleaned[f'{col}_nan'] = np.where(df_cleaned[col].isna(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_cleaned.groupby(['date','venue_name','race_number','market_name'])\n",
    "\n",
    "df_grouped_list = [df_grouped.get_group(x) for x in df_grouped.groups]\n",
    "len_sgl = len(df_grouped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.reset_index(level=list(range(4)), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped = df_grouped_list[:floor(.9*len_sgl)]\n",
    "test_grouped = df_grouped_list[floor(.9*len_sgl):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [int(idx[-1]) for group in train_grouped for idx in group.index]\n",
    "test_indices = [int(idx[-1]) for group in test_grouped for idx in group.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cleaned.loc[train_indices]\n",
    "test = df_cleaned.loc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Winning/Non-Placing: 153399\n",
      "Winning/Placing: 61735\n"
     ]
    }
   ],
   "source": [
    "zero_count = train['target'][train['target'] == 0].count()\n",
    "non_zero_count = train['target'][train['target'] != 0].count()\n",
    "\n",
    "print(\"Non-Winning/Non-Placing:\", zero_count)\n",
    "print(\"Winning/Placing:\", non_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_idx_list = train['target'][train['target'] != 0].index\n",
    "idx_list = []\n",
    "\n",
    "for i in range(zero_count - non_zero_count):\n",
    "    idx_list.append(rand.choice(non_zero_idx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306798, 459)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_new = pd.concat([train, train.loc[idx_list]])\n",
    "df_cleaned_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Winning/Non-Placing: 153399\n",
      "Winning/Placing: 153399\n"
     ]
    }
   ],
   "source": [
    "zero_count_new = df_cleaned_new['target'][df_cleaned_new['target'] == 0].count()\n",
    "non_zero_count_new = df_cleaned_new['target'][df_cleaned_new['target'] != 0].count()\n",
    "\n",
    "print(\"Non-Winning/Non-Placing:\", zero_count_new)\n",
    "print(\"Winning/Placing:\", non_zero_count_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_new.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_margin</th>\n",
       "      <th>bf_odds</th>\n",
       "      <th>bf_odds_two_mins_out</th>\n",
       "      <th>vic_tote</th>\n",
       "      <th>vic_tote_two_mins_out</th>\n",
       "      <th>nsw_tote</th>\n",
       "      <th>nsw_tote_two_mins_out</th>\n",
       "      <th>nsw_odds</th>\n",
       "      <th>betfair_slope</th>\n",
       "      <th>vic_tote_slope</th>\n",
       "      <th>...</th>\n",
       "      <th>overall_win_percent_norm_nan</th>\n",
       "      <th>overall_place_percent_norm_nan</th>\n",
       "      <th>track_win_percent_norm_nan</th>\n",
       "      <th>track_place_percent_norm_nan</th>\n",
       "      <th>distance_win_percent_norm_nan</th>\n",
       "      <th>distance_place_percent_norm_nan</th>\n",
       "      <th>condition_win_percent_norm_nan</th>\n",
       "      <th>condition_starts_norm_nan</th>\n",
       "      <th>condition_place_percent_norm_nan</th>\n",
       "      <th>prize_money_per_start_norm_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.80</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.80</td>\n",
       "      <td>15.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>11.20</td>\n",
       "      <td>11.70</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>46.40</td>\n",
       "      <td>37.10</td>\n",
       "      <td>40.40</td>\n",
       "      <td>35.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>13.20</td>\n",
       "      <td>14.20</td>\n",
       "      <td>11.80</td>\n",
       "      <td>13.60</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   previous_margin  bf_odds  bf_odds_two_mins_out  vic_tote  \\\n",
       "0             6.80     2.88                  3.00      2.30   \n",
       "1            20.80    15.00                 18.00     11.20   \n",
       "2             0.00    95.00                100.00     46.40   \n",
       "3             4.00    20.00                 17.00     13.20   \n",
       "4             0.00     2.74                  2.68      2.60   \n",
       "\n",
       "   vic_tote_two_mins_out  nsw_tote  nsw_tote_two_mins_out  nsw_odds  \\\n",
       "0                   3.50      2.40                   3.30      2.60   \n",
       "1                  11.70     12.00                  12.30     11.00   \n",
       "2                  37.10     40.40                  35.00     51.00   \n",
       "3                  14.20     11.80                  13.60     12.00   \n",
       "4                   3.20      3.40                   3.60      2.60   \n",
       "\n",
       "   betfair_slope  vic_tote_slope  ...  overall_win_percent_norm_nan  \\\n",
       "0          -0.00           -0.00  ...                             1   \n",
       "1          -0.00           -0.00  ...                             1   \n",
       "2           0.21            0.04  ...                             1   \n",
       "3           0.01           -0.01  ...                             1   \n",
       "4           0.00           -0.00  ...                             1   \n",
       "\n",
       "   overall_place_percent_norm_nan  track_win_percent_norm_nan  \\\n",
       "0                               0                           1   \n",
       "1                               0                           1   \n",
       "2                               0                           1   \n",
       "3                               0                           1   \n",
       "4                               0                           1   \n",
       "\n",
       "   track_place_percent_norm_nan  distance_win_percent_norm_nan  \\\n",
       "0                             1                              1   \n",
       "1                             1                              1   \n",
       "2                             1                              1   \n",
       "3                             1                              1   \n",
       "4                             1                              1   \n",
       "\n",
       "   distance_place_percent_norm_nan  condition_win_percent_norm_nan  \\\n",
       "0                                0                               1   \n",
       "1                                0                               1   \n",
       "2                                0                               1   \n",
       "3                                0                               1   \n",
       "4                                0                               1   \n",
       "\n",
       "   condition_starts_norm_nan  condition_place_percent_norm_nan  \\\n",
       "0                          0                                 1   \n",
       "1                          0                                 1   \n",
       "2                          0                                 1   \n",
       "3                          0                                 1   \n",
       "4                          0                                 1   \n",
       "\n",
       "   prize_money_per_start_norm_nan  \n",
       "0                               0  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "\n",
       "[5 rows x 459 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_cleaned_new.drop(['target'],axis=1), df_cleaned_new[['target']]\n",
    "X_test, y_test = test.drop(['target'],axis=1), test[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from time import time\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ridge = Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=0,\n",
    "                  solver='auto', tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap': [True, False],\n",
    "         'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "\n",
    "clf_rfr = RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=30, max_features='sqrt', max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=5, \n",
    "                                min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None, oob_score=False, random_state=0,\n",
    "                                verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfr = RandomizedSearchCV(estimator=clf_rfr, param_distributions=params, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function to split data and fit, predict, and score models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_train_model(model,X_train,y_train,X_test,y_test):\n",
    "    start=time()\n",
    "  \n",
    "    MAE_list_train=[]\n",
    "    MAE_list_val=[]\n",
    "    MAE_list_test=[]\n",
    "    R2_list_train=[]\n",
    "    R2_list_val=[]\n",
    "    R2_list_test=[]\n",
    "    \n",
    "    true_values_val = []\n",
    "    predict_values_val =[]\n",
    "    \n",
    "    true_values_test = []\n",
    "    predict_values_test =[]\n",
    "    \n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred1 = model.predict(X_train)\n",
    "    y_pred3 = model.predict(X_test)\n",
    "\n",
    "    precision_score\n",
    "\n",
    "    MAE_list_train.append(train_MAE)\n",
    "    MAE_list_test.append(test_MAE)\n",
    "    R2_list_train.append(train_R2)\n",
    "    R2_list_test.append(test_R2)\n",
    "    \n",
    "    true_values_test = true_values_test + list(zip(test_index,y_test))\n",
    "    predict_values_test = predict_values_test + list(zip(test_index,y_pred3))\n",
    "        \n",
    "    print()\n",
    "    print(f\"Train MAE: {np.mean(MAE_list_train)}\")\n",
    "    print(f\"Test MAE: {np.mean(MAE_list_test)}\")\n",
    "    print()\n",
    "    print(f\"Train R2: {np.mean(R2_list_train)}\")\n",
    "    print(f\"Test R2: {np.mean(R2_list_test)}\") \n",
    "    print()\n",
    "    print(f\"Data Folds Num: {data_folds_num}\")\n",
    "    print(f\"Time: {time()-start}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    total_picks = 0\n",
    "    correct_picks = []\n",
    "\n",
    "    for ((a,b),(c,d)) in list(zip(true_values_test,predict_values_test)):\n",
    "        if (b - 1 > 0) and (d - 1 > 0):\n",
    "            correct_picks.append(b)\n",
    "        if (d - 1 > 0):\n",
    "            total_picks += 1\n",
    "\n",
    "    win_odds_list = correct_picks\n",
    "\n",
    "    average_win = np.mean(win_odds_list)\n",
    "\n",
    "    print(\"Test\")\n",
    "    print(\"Total Horses:\",len(true_values))\n",
    "    print(\"Total Picks:\",total_picks)\n",
    "    print(\"Percent of Horses Picked:\",total_picks/len(true_values)*100)\n",
    "    print(\"Correct Picks:\",len(correct_picks))\n",
    "    print(\"Precision:\", len(correct_picks)/total_picks*100)\n",
    "    print(\"Average Win Odds:\",average_win)\n",
    "    print(\"Total Return:\",average_win*len(correct_picks)-total_picks)\n",
    "    print(\"Average Expected Return:\",(average_win*len(correct_picks)-total_picks)/total_picks)\n",
    "    print()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 2.6941819096645174\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtime_series_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf_rfr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mtime_series_train_model\u001b[1;34m(model, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m#         y_pred2 = model.predict(X_val)\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     y_pred3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 80\u001b[0m     train_MAE,train_R2\u001b[38;5;241m=\u001b[39m\u001b[43mmetrics_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m#         val_MAE,val_R2=metrics_function(y_val,y_pred2,\"val\")\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     test_MAE,test_R2\u001b[38;5;241m=\u001b[39mmetrics_function(y_test,y_pred3,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mmetrics_function\u001b[1;34m(target, pred, name)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(a,b)\n\u001b[0;32m     38\u001b[0m         exit()\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbet_list_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbet_list_pred\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     41\u001b[0m         r2_score(bet_list_target,bet_list_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:186\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_absolute_error\u001b[39m(\n\u001b[0;32m    131\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m ):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    190\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:90\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    the dtype argument passed to check_array.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m---> 90\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:797\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    795\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    798\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    799\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    800\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    801\u001b[0m         )\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    804\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "model = time_series_train_model(model=clf_rfr, \n",
    "                                X_train=X_train, \n",
    "                                y_train=y_train, \n",
    "                                X_test=X_test,\n",
    "                                y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
